{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# A Super Toy Regression Example"
      ],
      "metadata": {
        "id": "fX4IWOF7KTc7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To use GPU, model and train test data need to be loaded to GPU. cuda is needed as well to communicate with GPU. Other parts remain the same as trainig on CPU."
      ],
      "metadata": {
        "id": "1fuQoMrNJpNp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "c5hfpVdS0Ydh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare data\n",
        "This time we just use simple mock data and don't do train test split."
      ],
      "metadata": {
        "id": "CL2PLOpea1-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_values = [i for i in range(10)]\n",
        "x_train = np.array(x_values, dtype=np.float32)\n",
        "x_train = x_train.reshape(-1, 1)\n",
        "x_train.shape"
      ],
      "metadata": {
        "id": "-Vb51pg1VeIQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1077419a-4860-4442-8400-cca9db2a0ed4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_values = [2*i + 1 for i in x_values]\n",
        "y_train = np.array(y_values, dtype=np.float32)\n",
        "y_train = y_train.reshape(-1, 1)\n",
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMwNbwcgXkgn",
        "outputId": "fc948003-e8d4-45f7-9d75-92099159f973"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build model"
      ],
      "metadata": {
        "id": "sXLulzoYo-K8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearRegressionModel(nn.Module):\n",
        "  def __init__(self, input_dim, output_dim):\n",
        "    super(LinearRegressionModel, self).__init__()\n",
        "    self.linear = nn.Linear(input_dim, output_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.linear(x)\n",
        "    return out"
      ],
      "metadata": {
        "id": "eqko6eqDXoET"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = 1\n",
        "output_dim = 1\n",
        "\n",
        "model = LinearRegressionModel(input_dim, output_dim)\n",
        "\n",
        "# The following two lines is for GPU\n",
        "# device = torch.device(\"cuda: 0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# model.to(device)"
      ],
      "metadata": {
        "id": "neI1UeOYadm7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBHGRvhzt4fp",
        "outputId": "ec15b7f8-c05b-439f-9d9c-7ab70e87d7fe"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegressionModel(\n",
              "  (linear): Linear(in_features=1, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set hyperparameters and loss function"
      ],
      "metadata": {
        "id": "SLqEQrGy5pMw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 1000\n",
        "learning_rate = 0.01\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "vrD_OwicuCFn"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "\n",
        "  # convert np array to torch\n",
        "  inputs = torch.from_numpy(x_train)\n",
        "  labels = torch.from_numpy(y_train)\n",
        "\n",
        "  # the following is GPU version\n",
        "  # inputs = torch.from_numpy(x_train).to(device)\n",
        "  # labels = torch.from_numpy(y_train).to(device)\n",
        "\n",
        "  # clear gradient, otherwise it accumulates\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  # forward propagation\n",
        "  # don't even need to call the forward method!\n",
        "  outputs = model(inputs)\n",
        "\n",
        "  # compute loss\n",
        "  loss = criterion(outputs, labels)\n",
        "\n",
        "  # backward propagation\n",
        "  loss.backward()\n",
        "\n",
        "  # update parameters\n",
        "  optimizer.step()\n",
        "\n",
        "  # print results\n",
        "  if epoch % 50 ==0:\n",
        "    print(f\"epoch: {epoch}, loss: {loss.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4spGCVa156Jc",
        "outputId": "397f2b85-880f-4579-8b88-c338d685091c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, loss: 256.68243408203125\n",
            "epoch: 50, loss: 0.005956332199275494\n",
            "epoch: 100, loss: 0.0033808674197643995\n",
            "epoch: 150, loss: 0.001919012749567628\n",
            "epoch: 200, loss: 0.0010892294812947512\n",
            "epoch: 250, loss: 0.0006182418437674642\n",
            "epoch: 300, loss: 0.00035092068719677627\n",
            "epoch: 350, loss: 0.00019919045735150576\n",
            "epoch: 400, loss: 0.00011306182568660006\n",
            "epoch: 450, loss: 6.417484837584198e-05\n",
            "epoch: 500, loss: 3.642580486484803e-05\n",
            "epoch: 550, loss: 2.067586683551781e-05\n",
            "epoch: 600, loss: 1.1736109627236146e-05\n",
            "epoch: 650, loss: 6.662109626631718e-06\n",
            "epoch: 700, loss: 3.7825798244739417e-06\n",
            "epoch: 750, loss: 2.1465443751367275e-06\n",
            "epoch: 800, loss: 1.218227907884284e-06\n",
            "epoch: 850, loss: 6.917414907547936e-07\n",
            "epoch: 900, loss: 3.9262766904357704e-07\n",
            "epoch: 950, loss: 2.2278811684373068e-07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use the trained model to predict results"
      ],
      "metadata": {
        "id": "6cT7Fjcp9rxK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predicted = model(torch.from_numpy(x_train))\n",
        "# convert to numpy, for later usage like matplotlib etc\n",
        "predicted = predicted.data.numpy()\n",
        "predicted"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpikZQ8J6zBg",
        "outputId": "ef0c7071-f345-4edd-ba9f-259035ab2fa0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.0006608],\n",
              "       [ 3.0005555],\n",
              "       [ 5.00045  ],\n",
              "       [ 7.0003448],\n",
              "       [ 9.000239 ],\n",
              "       [11.000134 ],\n",
              "       [13.000029 ],\n",
              "       [14.999923 ],\n",
              "       [16.999817 ],\n",
              "       [18.999712 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save model"
      ],
      "metadata": {
        "id": "ahO2JAGL98Y7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# saved as dictionary\n",
        "# save to where??\n",
        "torch.save(model.state_dict(), 'model.pkl')"
      ],
      "metadata": {
        "id": "H_WaajIf9Qiu"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load model"
      ],
      "metadata": {
        "id": "Tt1-P6fF-Ejv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('model.pkl'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zG3LNvpM-ED9",
        "outputId": "e228dcf0-3c04-4d86-9f30-3f1c658b479b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    }
  ]
}